# Importa a biblioteca Streamlit para criar a interface web
import streamlit as st
# Importa a biblioteca pandas para manipula√ß√£o de dados em DataFrames
import pandas as pd
# Importa a biblioteca numpy para opera√ß√µes num√©ricas, embora n√£o explicitamente usada na sele√ß√£o, √© comum com pandas
import numpy as np
# Importa o m√≥dulo io para trabalhar com fluxos de bytes/arquivos em mem√≥ria
import io
# Importa o m√≥dulo re para express√µes regulares, usado em fun√ß√µes de utilidade
import re
# Importa a biblioteca chardet para detec√ß√£o de codifica√ß√£o de arquivos
import chardet
# Importa o parser de data da biblioteca dateutil para an√°lise flex√≠vel de datas
from dateutil import parser

# Configura√ß√µes iniciais da p√°gina Streamlit, como t√≠tulo e layout
st.set_page_config(page_title="Limpeza de Dados CSV", layout="wide")


# Utilit√°rios


# Define uma fun√ß√£o para detectar a codifica√ß√£o de um arquivo a partir de seus bytes
def detect_encoding(file_bytes: bytes) -> str:
    # Usa a biblioteca chardet para detectar a codifica√ß√£o dos bytes do arquivo
    result = chardet.detect(file_bytes)
    # Extrai a codifica√ß√£o do resultado, ou assume "utf-8" se n√£o for detectada
    enc = result.get("encoding") or "utf-8"
    # Retorna a codifica√ß√£o detectada ou padr√£o
    return enc

# Define uma fun√ß√£o para normalizar o nome de uma coluna
def normalize_colname(name: str) -> str:
    # Importa a biblioteca re para express√µes regulares (j√° importada no topo, mas re-importada aqui localmente)
    import re
    # Converte o nome para string, remove espa√ßos extras no in√≠cio/fim e converte para min√∫sculas
    name = str(name).strip().lower()
    # Substitui um ou mais espa√ßos por um √∫nico underscore
    name = re.sub(r"\s+", "_", name)
    # Remove todos os caracteres que n√£o s√£o letras, n√∫meros ou underscores
    name = re.sub(r"[^\w_]", "", name)
    # Substitui m√∫ltiplos underscores consecutivos por um √∫nico underscore e remove underscores no in√≠cio/fim
    name = re.sub(r"_+", "_", name).strip("_")
    # Se o nome resultar em uma string vazia ap√≥s a normaliza√ß√£o, define como "col"
    if name == "":
        name = "col"
    # Retorna o nome da coluna normalizado
    return name



# Define uma fun√ß√£o chamada make_unique que recebe uma lista de nomes
def make_unique(names):
    """Garante nomes √∫nicos: a, a_2, a_3...""" # Docstring: explica o prop√≥sito da fun√ß√£o
    seen = {} # Inicializa um dicion√°rio vazio para armazenar a contagem de cada nome
    out = [] # Inicializa uma lista vazia para armazenar os nomes √∫nicos resultantes
    # Itera sobre cada nome na lista de nomes de entrada
    for n in names:
        # Verifica se o nome atual ainda n√£o foi visto (n√£o est√° no dicion√°rio seen)
        if n not in seen:
            seen[n] = 1 # Se n√£o foi visto, adiciona-o ao dicion√°rio com contagem 1
            out.append(n) # Adiciona o nome original √† lista de sa√≠da
        # Se o nome j√° foi visto
        else:
            seen[n] += 1 # Incrementa a contagem desse nome no dicion√°rio
            out.append(f"{n}_{seen[n]}") # Adiciona o nome com um sufixo num√©rico (ex: "nome_2") √† lista de sa√≠da
    return out # Retorna a lista de nomes √∫nicos

def try_parse_datetime(series: pd.Series, sample_size=200) -> bool:
    # Define uma fun√ß√£o para tentar inferir se uma s√©rie Pandas cont√©m datas
    # A fun√ß√£o recebe uma s√©rie Pandas e um tamanho de amostra (padr√£o 200)
    # E retorna True se uma alta porcentagem da amostra for convert√≠vel para data, False caso contr√°rio

    # Extrai valores n√£o nulos da s√©rie e converte-os para string
    s = series.dropna().astype(str)
    # Se a s√©rie resultante estiver vazia ap√≥s remover nulos, n√£o h√° o que verificar, retorna False
    if s.empty:
        return False
    # Seleciona uma amostra aleat√≥ria dos valores (ou todos se o tamanho da s√©rie for menor que sample_size)
    # O random_state garante reprodutibilidade da amostra
    s = s.sample(min(sample_size, len(s)), random_state=42)
    # Inicializa um contador para o n√∫mero de valores que puderam ser parseados como data
    ok = 0
    # Itera sobre cada valor na amostra
    for v in s:
        try:
            # Tenta fazer o parse do valor para datetime usando o parser flex√≠vel da dateutil
            # fuzzy=True permite ignorar partes da string que n√£o s√£o datas (ex: "relat√≥rio 2023-01-01")
            _ = parser.parse(v, fuzzy=True)
            # Se o parse for bem-sucedido, incrementa o contador 'ok'
            ok += 1
        except Exception:
            # Se ocorrer um erro ao tentar o parse (o valor n√£o √© uma data v√°lida), ignora
            pass
    # Retorna True se pelo menos 70% (0.7) dos valores da amostra puderam ser parseados como data, caso contr√°rio False
    return (ok / len(s)) >= 0.7

# Define uma fun√ß√£o chamada to_datetime_safe que recebe uma s√©rie Pandas
def to_datetime_safe(series: pd.Series) -> pd.Series:
    # Tenta converter a s√©rie para o tipo datetime do Pandas
    # errors="coerce" far√° com que valores que n√£o podem ser convertidos se tornem NaT (Not a Time)
    # infer_datetime_format=True permite que o Pandas tente inferir o formato da data para uma convers√£o mais r√°pida
    return pd.to_datetime(series, errors="coerce", infer_datetime_format=True)

def coerce_numeric(series: pd.Series) -> pd.Series:
    # tenta converter removendo separadores comuns
    s = series.astype(str).str.strip()
    # troca v√≠rgula decimal por ponto quando parece num√©rico
    s = s.str.replace(".", "", regex=False)  # remove separador de milhar comum (.)
    s = s.str.replace(",", ".", regex=False)  # decimal v√≠rgula -> ponto
    return pd.to_numeric(s, errors="coerce")

# Define uma fun√ß√£o chamada download_button_csv que recebe um DataFrame, um nome de arquivo e um separador
def download_button_csv(df: pd.DataFrame, filename="dados_tratados.csv", sep=";"):
    # Converte o DataFrame para uma string CSV, sem o √≠ndice, usando o separador especificado, e codifica para bytes com BOM (para Excel)
    csv_bytes = df.to_csv(index=False, sep=sep).encode("utf-8-sig")  # <- utf-8-sig pro Excel
    # Cria um bot√£o de download no Streamlit
    st.download_button(
        "‚¨áÔ∏è Baixar CSV tratado (Excel)", # Texto exibido no bot√£o
        data=csv_bytes,                 # Dados a serem baixados
        file_name=filename,             # Nome do arquivo quando baixado
        mime="text/csv",                # Tipo MIME do arquivo
        use_container_width=True        # O bot√£o ocupa a largura total do cont√™iner
    )


# Define uma fun√ß√£o chamada df_info_summary que recebe um DataFrame e retorna um novo DataFrame com um resumo das colunas
def df_info_summary(df: pd.DataFrame) -> pd.DataFrame:
    # Retorna um novo DataFrame com informa√ß√µes sumarizadas de cada coluna do DataFrame de entrada
    return pd.DataFrame({
        "coluna": df.columns,                                       # Lista os nomes das colunas
        "dtype": [str(df[c].dtype) for c in df.columns],            # Lista os tipos de dados de cada coluna (como string)
        "nulos": [int(df[c].isna().sum()) for c in df.columns],     # Conta o n√∫mero de valores nulos em cada coluna
        "percent_nulos": [float(df[c].isna().mean() * 100) for c in df.columns], # Calcula o percentual de nulos em cada coluna
        "unicos": [int(df[c].nunique(dropna=True)) for c in df.columns], # Conta o n√∫mero de valores √∫nicos (ignorando nulos) em cada coluna
    })


# Estado

# Verifica se a chave 'df_original' n√£o existe no st.session_state (estado da sess√£o do Streamlit)
if "df_original" not in st.session_state:
    # Se n√£o existir, inicializa 'df_original' como None no estado da sess√£o
    st.session_state.df_original = None
# Verifica se a chave 'df' n√£o existe no st.session_state
if "df" not in st.session_state:
    # Se n√£o existir, inicializa 'df' como None no estado da sess√£o (este ser√° o DataFrame atual modificado)
    st.session_state.df = None
# Verifica se a chave 'log' n√£o existe no st.session_state
if "log" not in st.session_state:
    # Se n√£o existir, inicializa 'log' como uma lista vazia no estado da sess√£o (para registrar as a√ß√µes)
    st.session_state.log = []

# Define uma fun√ß√£o chamada 'log_step' que aceita uma mensagem (string)
def log_step(msg: str):
    # Adiciona a mensagem fornecida √† lista 'log' no estado da sess√£o
    st.session_state.log.append(msg)


# UI

# Define o t√≠tulo principal da aplica√ß√£o Streamlit
st.title("üßº Limpeza de Dados (CSV)")
# Adiciona uma pequena descri√ß√£o/legenda abaixo do t√≠tulo
st.caption("Upload ‚Üí Diagn√≥stico ‚Üí Limpeza em etapas ‚Üí Download do CSV tratado")

# Inicia um bloco de c√≥digo que ser√° renderizado na barra lateral do Streamlit
with st.sidebar:
    # Adiciona um cabe√ßalho para a se√ß√£o de upload na barra lateral
    st.header("üì• Upload")
    # Cria um widget de upload de arquivo para arquivos CSV
    uploaded = st.file_uploader("Selecione um arquivo CSV", type=["csv"])

    # Adiciona um divisor visual na barra lateral
    st.divider()
    # Adiciona um cabe√ßalho para a se√ß√£o de configura√ß√µes de leitura
    st.header("‚öôÔ∏è Configura√ß√µes de leitura")
    # Cria um seletor para o separador de colunas do CSV, com "," como padr√£o
    sep = st.selectbox("Separador", options=[",", ";", "\t", "|"], index=0)
    # Cria um seletor para o separador decimal (apenas para refer√™ncia na UI, n√£o afeta leitura diretamente aqui)
    decimal = st.selectbox("Decimal (apenas refer√™ncia)", options=[".", ","], index=0)
    # Cria uma caixa de sele√ß√£o para indicar se o CSV tem cabe√ßalho, marcada como verdadeira por padr√£o
    has_header = st.checkbox("Arquivo tem cabe√ßalho?", value=True)
    # Cria um campo de texto para o usu√°rio inserir valores a serem considerados como NA (Not Applicable/Nulo)
    na_values_text = st.text_input("Valores para considerar como NA (separe por v√≠rgula)", "NA,NaN,null,NULL,")
    # Processa a string de NA_values para criar uma lista de strings, removendo espa√ßos e entradas vazias
    na_values = [x.strip() for x in na_values_text.split(",") if x.strip() != ""]
    # Adiciona outro divisor visual na barra lateral
    st.divider()

    # Cria um bot√£o "Resetar tudo" na barra lateral
    if st.button("üîÑ Resetar tudo", use_container_width=True):
        # Quando clicado, redefine o DataFrame original para None no estado da sess√£o
        st.session_state.df_original = None
        # Redefine o DataFrame atual para None no estado da sess√£o
        st.session_state.df = None
        # Limpa o log de a√ß√µes no estado da sess√£o
        st.session_state.log = []
        # For√ßa o Streamlit a reroduzir o script desde o in√≠cio, limpando a UI e o estado
        st.rerun()


# Carregar CSV

# Verifica se um arquivo foi carregado (uploaded √© diferente de None) E se o DataFrame atual ainda n√£o foi carregado na sess√£o
if uploaded is not None and st.session_state.df is None:
    # Obt√©m o conte√∫do do arquivo carregado como bytes
    file_bytes = uploaded.getvalue()
    # Detecta a codifica√ß√£o do arquivo usando a fun√ß√£o 'detect_encoding'
    enc = detect_encoding(file_bytes)

    try:
        # Tenta ler o arquivo CSV usando pandas.read_csv
        df = pd.read_csv(
            # Cria um fluxo de bytes em mem√≥ria a partir dos bytes do arquivo
            io.BytesIO(file_bytes),
            # Define o separador de colunas conforme selecionado na UI
            sep=sep,
            # Define a codifica√ß√£o detectada
            encoding=enc,
            # Define o cabe√ßalho: 0 se 'has_header' for True, None caso contr√°rio
            header=0 if has_header else None,
            # Define os valores a serem considerados como NA (nulos)
            na_values=na_values
        )
    except Exception:
        # Em caso de erro na leitura com a codifica√ß√£o detectada, tenta um fallback simples
        df = pd.read_csv(
            # Cria um fluxo de bytes em mem√≥ria a partir dos bytes do arquivo
            io.BytesIO(file_bytes),
            # Define o separador de colunas conforme selecionado na UI
            sep=sep,
            # Usa "utf-8" como codifica√ß√£o de fallback
            encoding="utf-8",
            # Define o cabe√ßalho: 0 se 'has_header' for True, None caso contr√°rio
            header=0 if has_header else None,
            # Define os valores a serem considerados como NA (nulos)
            na_values=na_values
        )

    # Se o arquivo n√£o tiver cabe√ßalho (has_header √© False)
    if not has_header:
        # Atribui nomes de coluna gen√©ricos (ex: "col_0", "col_1")
        df.columns = [f"col_{i}" for i in range(df.shape[1])]

    # Armazena uma c√≥pia do DataFrame original no estado da sess√£o
    st.session_state.df_original = df.copy()
    # Armazena uma c√≥pia do DataFrame atual (que ser√° modificado) no estado da sess√£o
    st.session_state.df = df.copy()
    # Reinicia o log de a√ß√µes
    st.session_state.log = []
    # Registra a a√ß√£o de carregamento do arquivo no log
    log_step(f"Arquivo carregado com {df.shape[0]} linhas e {df.shape[1]} colunas. (encoding detectado: {enc})")

# Atribui o DataFrame atual da sess√£o (st.session_state.df) √† vari√°vel local 'df'
df = st.session_state.df

# Verifica se o DataFrame 'df' √© None (o que significa que nenhum arquivo foi carregado ainda)
if df is None:
    # Exibe uma mensagem informativa na interface do Streamlit
    st.info("Fa√ßa o upload de um CSV na barra lateral para come√ßar.")
    # Interrompe a execu√ß√£o do script Streamlit neste ponto, aguardando o upload do arquivo
    st.stop()


# Vis√£o geral

# Cria duas colunas na interface do Streamlit, com propor√ß√µes de largura 2 para 1 e um espa√ßamento "large"
colA, colB = st.columns([2, 1], gap="large")

# Inicia um bloco de c√≥digo que ser√° renderizado na primeira coluna (colA)
with colA:
    # Adiciona um subt√≠tulo √† coluna
    st.subheader("Pr√©via do dataset")
    # Exibe uma pr√©via das primeiras 50 linhas do DataFrame 'df' em um widget de tabela, usando a largura total do cont√™iner
    st.dataframe(df.head(50), use_container_width=True)

# Inicia um bloco de c√≥digo que ser√° renderizado na segunda coluna (colB)
with colB:
    # Adiciona um subt√≠tulo √† coluna
    st.subheader("üìä Resumo")
    # Exibe o n√∫mero de linhas do DataFrame
    st.write(f"**Linhas:** {df.shape[0]}")
    # Exibe o n√∫mero de colunas do DataFrame
    st.write(f"**Colunas:** {df.shape[1]}")
    # Exibe o n√∫mero de linhas duplicadas no DataFrame (convertido para inteiro)
    st.write(f"**Duplicadas (linhas):** {int(df.duplicated().sum())}")
    # Exibe o n√∫mero total de c√©lulas nulas em todo o DataFrame (convertido para inteiro)
    st.write(f"**C√©lulas nulas (total):** {int(df.isna().sum().sum())}")
    # Adiciona uma linha vazia para espa√ßamento visual
    st.write("")
    # Adiciona uma legenda para a tabela de resumo por coluna
    st.caption("Detalhe por coluna:")
    # Exibe um DataFrame com um resumo detalhado por coluna (criado pela fun√ß√£o df_info_summary)
    # usando a largura total do cont√™iner e com altura fixa de 260 pixels
    st.dataframe(df_info_summary(df), use_container_width=True, height=260)

# Adiciona um divisor visual horizontal na interface do Streamlit
st.divider()

# Etapas (Acorde√µes)

# 1) Padronizar nomes de colunas
with st.expander("1) üè∑Ô∏è Padronizar nomes de colunas", expanded=False):
    # Exibe uma mensagem de sugest√£o para o usu√°rio sobre como padronizar nomes de colunas
    st.write("Sugest√£o: remover espa√ßos, padronizar para min√∫sculas e trocar espa√ßos por `_`.")
    # Cria um DataFrame tempor√°rio para pr√©-visualizar a mudan√ßa dos nomes das colunas
    preview_cols = pd.DataFrame({
        # Coluna "antes" mostra os nomes atuais das colunas do DataFrame
        "antes": st.session_state.df.columns,
        # Coluna "depois" mostra como os nomes ficariam ap√≥s a normaliza√ß√£o usando a fun√ß√£o normalize_colname
        "depois": [normalize_colname(c) for c in st.session_state.df.columns]
    })
    # Exibe o DataFrame de pr√©-visualiza√ß√£o na interface do Streamlit, ocupando a largura total do cont√™iner
    st.dataframe(preview_cols, use_container_width=True)

    # Calcula o n√∫mero de nomes de coluna que se tornariam duplicados ap√≥s a normaliza√ß√£o
    dups = pd.Series([normalize_colname(c) for c in df.columns]).duplicated().sum()
    # Exibe o n√∫mero de poss√≠veis nomes duplicados que ser√£o tratados pela fun√ß√£o make_unique
    st.write(f"Poss√≠veis nomes duplicados ap√≥s padronizar: **{int(dups)}**")

    # Cria um bot√£o para aplicar a padroniza√ß√£o dos nomes das colunas
    if st.button("Aplicar padroniza√ß√£o de nomes", key="apply_colnames"):
        # Armazena os nomes das colunas atuais em uma lista
        old_cols = list(df.columns)
        # Gera uma nova lista de nomes de colunas padronizados usando a fun√ß√£o normalize_colname
        new_cols = [normalize_colname(c) for c in old_cols]
        # Garante que os novos nomes de colunas sejam √∫nicos, adicionando sufixos se necess√°rio (ex: "col_2")
        new_cols = make_unique(new_cols)

        # Cria uma c√≥pia do DataFrame para evitar modificar o DataFrame original diretamente em caso de re-execu√ß√£o
        df = df.copy()
        # Atribui os novos nomes padronizados e √∫nicos √†s colunas do DataFrame
        df.columns = new_cols
        # Atualiza o DataFrame na sess√£o do Streamlit com as colunas renomeadas
        st.session_state.df = df

        # Registra a a√ß√£o no log de passos
        log_step("Nomes de colunas padronizados e tornados √∫nicos.")
        # Exibe uma mensagem de sucesso para o usu√°rio
        st.success("Aplicado!")
        # For√ßa o Streamlit a reroduzir o script para atualizar a interface com os novos nomes de colunas
        st.rerun()


# 2) Remover espa√ßos extras em textos
with st.expander("2) ‚úÇÔ∏è Limpar textos (trim, espa√ßos duplicados)", expanded=False):
    # Filtra as colunas do DataFrame que possuem o tipo de dado 'object' (geralmente strings/textos)
    text_cols = [c for c in df.columns if df[c].dtype == "object"]
    # Cria um multiselect no Streamlit para o usu√°rio selecionar quais colunas de texto aplicar a limpeza
    # Por padr√£o, pr√©-seleciona as primeiras 10 colunas de texto (ou todas se houver menos de 10)
    selected = st.multiselect("Selecione colunas de texto", options=text_cols, default=text_cols[:10])
    # Cria uma caixa de sele√ß√£o para permitir ao usu√°rio decidir se deseja substituir m√∫ltiplos espa√ßos por um √∫nico
    replace_multi_space = st.checkbox("Trocar m√∫ltiplos espa√ßos por 1 espa√ßo", value=True)
    # Cria um bot√£o para aplicar as opera√ß√µes de limpeza de texto
    if st.button("Aplicar limpeza de texto", key="apply_text"):
        # Itera sobre cada coluna selecionada pelo usu√°rio para aplicar a limpeza
        for c in selected:
            # Converte a coluna para o tipo de string do pandas (permite valores nulos)
            s = df[c].astype("string")
            # Remove espa√ßos em branco do in√≠cio e do fim de cada string na s√©rie
            s = s.str.strip()
            # Verifica se a op√ß√£o de substituir m√∫ltiplos espa√ßos foi selecionada
            if replace_multi_space:
                # Substitui um ou mais espa√ßos consecutivos por um √∫nico espa√ßo
                s = s.str.replace(r"\s+", " ", regex=True)
            # Atualiza a coluna original no DataFrame com a s√©rie de strings limpa
            df[c] = s
        # Atualiza o DataFrame na sess√£o do Streamlit com as altera√ß√µes
        st.session_state.df = df
        # Registra a a√ß√£o de limpeza de texto no log de passos
        log_step(f"Limpeza de texto aplicada em {len(selected)} colunas (strip + normaliza√ß√£o de espa√ßos).")
        # Exibe uma mensagem de sucesso para o usu√°rio
        st.success("Aplicado!")

# 3) Tipagem autom√°tica (datas e n√∫meros)
with st.expander("3) üî¢ Tipagem autom√°tica (detectar datas e n√∫meros)", expanded=False):
    # Exibe uma mensagem informativa para o usu√°rio sobre o prop√≥sito desta se√ß√£o.
    st.write("Converte colunas `object` que parecem n√∫meros/datas.")
    # Cria uma caixa de sele√ß√£o para permitir ao usu√°rio decidir se tenta converter colunas para n√∫meros.
    # O valor padr√£o √© True (marcado).
    convert_numbers = st.checkbox("Tentar converter n√∫meros (ex: '1.234,56')", value=True)
    # Cria uma caixa de sele√ß√£o para permitir ao usu√°rio decidir se tenta converter colunas para datas.
    # O valor padr√£o √© True (marcado).
    convert_dates = st.checkbox("Tentar converter datas", value=True)

    # Cria um bot√£o para aplicar as opera√ß√µes de tipagem autom√°tica.
    if st.button("Aplicar tipagem autom√°tica", key="apply_types"):
        # Inicializa um contador para o n√∫mero de colunas cujo tipo de dado foi alterado.
        changed = 0

        # Bloco de c√≥digo para tentar converter colunas para n√∫meros.
        # Verifica se o usu√°rio optou por converter n√∫meros.
        if convert_numbers:
            # Itera sobre cada coluna no DataFrame.
            for c in df.columns:
                # Verifica se o tipo de dado da coluna atual √© 'object' (geralmente strings).
                if df[c].dtype == "object":
                    # Tenta converter a coluna para um tipo num√©rico usando a fun√ß√£o `coerce_numeric`.
                    converted = coerce_numeric(df[c])
                    # Calcula o n√∫mero de valores n√£o nulos na coluna original.
                    non_null = df[c].notna().sum()
                    # Verifica se h√° valores n√£o nulos na coluna.
                    if non_null > 0:
                        # Calcula a propor√ß√£o de valores que foram convertidos com sucesso para num√©ricos (n√£o nulos na s√©rie convertida)
                        # em rela√ß√£o aos valores n√£o nulos da s√©rie original.
                        ratio = converted.notna().sum() / non_null
                        # Se a propor√ß√£o for 70% ou mais (o que significa que a maioria dos valores √© num√©rica),
                        # aplica a convers√£o ao DataFrame.
                        if ratio >= 0.7:
                            # Atualiza a coluna no DataFrame com a s√©rie num√©rica convertida.
                            df[c] = converted
                            # Incrementa o contador de colunas alteradas.
                            changed += 1

        # Bloco de c√≥digo para tentar converter colunas para datas.
        # Verifica se o usu√°rio optou por converter datas.
        if convert_dates:
            # Itera sobre cada coluna no DataFrame.
            for c in df.columns:
                # Verifica se o tipo de dado da coluna atual √© 'object' (geralmente strings que podem conter datas).
                if df[c].dtype == "object":
                    # Tenta inferir se a coluna cont√©m datas utilizando a fun√ß√£o `try_parse_datetime`.
                    # Se `try_parse_datetime` retornar True, significa que a coluna provavelmente √© de data.
                    # Se a fun√ß√£o try_parse_datetime retornar True (indicando que a coluna parece conter datas)
                    if try_parse_datetime(df[c]):
                        # Tenta converter a coluna para o tipo datetime de forma segura, tratando erros
                        dt = to_datetime_safe(df[c])
                        # Verifica se a propor√ß√£o de valores n√£o nulos ap√≥s a convers√£o para datetime √© >= 70% dos valores n√£o nulos originais
                        if dt.notna().sum() >= 0.7 * df[c].notna().sum():
                            # Atribui a s√©rie de datetime convertida de volta √† coluna original no DataFrame
                            df[c] = dt
                            # Incrementa o contador de colunas alteradas com sucesso
                            changed += 1


        # Atualiza o DataFrame na sess√£o do Streamlit com as altera√ß√µes de tipagem.
        st.session_state.df = df
        # Registra a a√ß√£o de tipagem autom√°tica no log, indicando quantas colunas foram alteradas.
        log_step(f"Tipagem autom√°tica aplicada. Colunas convertidas: {changed}.")
        # Exibe uma mensagem de sucesso na interface do Streamlit, mostrando o n√∫mero de colunas convertidas.
        st.success(f"Aplicado! Colunas convertidas: {changed}")

# 4) Duplicadas
with st.expander("4) üß© Remover linhas duplicadas", expanded=False):
    # Calcula o n√∫mero de linhas duplicadas no DataFrame e armazena em 'dups'
    dups = int(df.duplicated().sum())
    # Exibe na interface do Streamlit o n√∫mero de duplicadas detectadas
    st.write(f"Duplicadas detectadas: **{dups}**")
    # Cria um seletor no Streamlit para escolher qual ocorr√™ncia de duplicata manter (primeira ou √∫ltima)
    keep = st.selectbox("Manter qual ocorr√™ncia?", options=["first", "last"], index=0)
    # Cria um bot√£o para remover duplicadas, que √© desabilitado se n√£o houver duplicatas (dups == 0)
    if st.button("Remover duplicadas", key="apply_dups", disabled=(dups == 0)):
        # Armazena o n√∫mero de linhas antes da remo√ß√£o para calcular quantas foram removidas
        before = df.shape[0]
        # Remove as linhas duplicadas do DataFrame, mantendo a ocorr√™ncia especificada pelo usu√°rio
        df = df.drop_duplicates(keep=keep)
        # Atualiza o DataFrame no estado da sess√£o do Streamlit com as duplicadas removidas
        st.session_state.df = df
        # Registra a a√ß√£o no log, informando quantas linhas foram removidas e qual estrat√©gia foi usada
        log_step(f"Linhas duplicadas removidas (keep='{keep}'). {before - df.shape[0]} linhas removidas.")
        # Exibe uma mensagem de sucesso na interface do Streamlit
        st.success("Aplicado!")

# 5) Valores nulos
with st.expander("5) üï≥Ô∏è Tratamento de valores nulos", expanded=False):
    # Exibe uma mensagem introdut√≥ria para o usu√°rio sobre o tratamento de nulos.
    st.write("Escolha uma estrat√©gia por tipo de coluna.")
    # Filtra as colunas do DataFrame que s√£o de tipo num√©rico.
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    # Filtra as colunas do DataFrame que s√£o de tipo 'object' ou string (categ√≥ricas/textos).
    cat_cols = [c for c in df.columns if df[c].dtype == "object" or pd.api.types.is_string_dtype(df[c])]
    # Filtra as colunas do DataFrame que s√£o de tipo datetime.
    dt_cols  = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]

    # Exibe um markdown para categorizar as op√ß√µes de colunas num√©ricas.
    st.markdown("**Num√©ricas:**")
    # Cria um seletor para a estrat√©gia de tratamento de nulos para colunas num√©ricas.
    num_strategy = st.selectbox("Estrat√©gia (num√©ricas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com 0", "Preencher com m√©dia", "Preencher com mediana"], index=0)
    # Cria um multiselect para o usu√°rio escolher quais colunas num√©ricas aplicar a estrat√©gia.
    num_sel = st.multiselect("Colunas num√©ricas", options=num_cols, default=num_cols)

    # Exibe um markdown para categorizar as op√ß√µes de colunas categ√≥ricas/textos.
    st.markdown("**Categ√≥ricas/Textos:**")
    # Cria um seletor para a estrat√©gia de tratamento de nulos para colunas categ√≥ricas.
    cat_strategy = st.selectbox("Estrat√©gia (categ√≥ricas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com 'DESCONHECIDO'", "Preencher com moda (mais frequente)"], index=0)
    # Cria um multiselect para o usu√°rio escolher quais colunas categ√≥ricas aplicar a estrat√©gia.
    cat_sel = st.multiselect("Colunas categ√≥ricas", options=cat_cols, default=cat_cols)

    # Exibe um markdown para categorizar as op√ß√µes de colunas de datas.
    st.markdown("**Datas:**")
    # Cria um seletor para a estrat√©gia de tratamento de nulos para colunas de datas.
    dt_strategy = st.selectbox("Estrat√©gia (datas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com data m√≠nima", "Preencher com data m√°xima"], index=0)
    # Cria um multiselect para o usu√°rio escolher quais colunas de data aplicar a estrat√©gia.
    dt_sel = st.multiselect("Colunas datetime", options=dt_cols, default=dt_cols)

    # Cria um bot√£o para aplicar o tratamento de nulos selecionado.
    if st.button("Aplicar tratamento de nulos", key="apply_na"):
        # Armazena o n√∫mero de linhas antes do tratamento para calcular as removidas.
        before = df.shape[0]

        # Inicia o tratamento para colunas num√©ricas.
        # Verifica se uma estrat√©gia foi selecionada e se h√° colunas num√©ricas escolhidas.
        if num_strategy != "N√£o mexer" and len(num_sel) > 0:
            # Se a estrat√©gia for remover linhas com NA.
            if num_strategy == "Remover linhas com NA":
                # Remove linhas onde as colunas num√©ricas selecionadas t√™m valores nulos.
                df = df.dropna(subset=num_sel)
            # Se a estrat√©gia for preencher valores nulos.
            else:
                # Itera sobre cada coluna num√©rica selecionada.
                for c in num_sel:
                    # Se a estrat√©gia for preencher com 0.
                    if num_strategy == "Preencher com 0":
                        # Preenche os valores nulos da coluna com 0.
                        df[c] = df[c].fillna(0)
                    # Se a estrat√©gia for preencher com a m√©dia.
                    elif num_strategy == "Preencher com m√©dia":
                        # Preenche os valores nulos da coluna com a m√©dia.
                        df[c] = df[c].fillna(df[c].mean())
                    # Se a estrat√©gia for preencher com a mediana.
                    elif num_strategy == "Preencher com mediana":
                        # Preenche os valores nulos da coluna com a mediana.
                        df[c] = df[c].fillna(df[c].median())

        # Inicia o tratamento para colunas categ√≥ricas.
        # Verifica se uma estrat√©gia foi selecionada e se h√° colunas categ√≥ricas escolhidas.
        if cat_strategy != "N√£o mexer" and len(cat_sel) > 0:
            # Se a estrat√©gia for remover linhas com NA.
            if cat_strategy == "Remover linhas com NA":
                # Remove linhas onde as colunas categ√≥ricas selecionadas t√™m valores nulos.
                df = df.dropna(subset=cat_sel)
            # Se a estrat√©gia for preencher valores nulos.
            else:
                # Itera sobre cada coluna categ√≥rica selecionada.
                for c in cat_sel:
                    # Se a estrat√©gia for preencher com 'DESCONHECIDO'.
                    if cat_strategy == "Preencher com 'DESCONHECIDO'":
                        # Preenche os valores nulos da coluna com a string "DESCONHECIDO".
                        df[c] = df[c].fillna("DESCONHECIDO")
                    # Se a estrat√©gia for preencher com a moda (valor mais frequente).
                    elif cat_strategy == "Preencher com moda (mais frequente)":
                        # Calcula a moda da coluna, ignorando nulos.
                        moda = df[c].mode(dropna=True)
                        # Define o valor de preenchimento como a primeira moda ou "DESCONHECIDO" se n√£o houver moda.
                        fill = moda.iloc[0] if len(moda) else "DESCONHECIDO"
                        # Preenche os valores nulos da coluna com o valor de preenchimento.
                        df[c] = df[c].fillna(fill)

        # Inicia o tratamento para colunas de datas.
        # Verifica se uma estrat√©gia foi selecionada e se h√° colunas de datas escolhidas.
        if dt_strategy != "N√£o mexer" and len(dt_sel) > 0:
            # Se a estrat√©gia for remover linhas com NA.
            if dt_strategy == "Remover linhas com NA":
                # Remove linhas onde as colunas de data selecionadas t√™m valores nulos.
                df = df.dropna(subset=dt_sel)
            # Se a estrat√©gia for preencher valores nulos.
            else:
                # Itera sobre cada coluna de data selecionada.
                for c in dt_sel:
                    # Se a estrat√©gia for preencher com a data m√≠nima.
                    if dt_strategy == "Preencher com data m√≠nima":
                        # Verifica se h√° valores n√£o nulos na coluna para calcular a data m√≠nima.
                        if df[c].dropna().empty:
                            # Se a coluna estiver vazia ap√≥s remover nulos, pula para a pr√≥xima.
                            continue
                        # Preenche os valores nulos da coluna com a data m√≠nima.
                        df[c] = df[c].fillna(df[c].min())
                    # Se a estrat√©gia for preencher com a data m√°xima.
                    elif dt_strategy == "Preencher com data m√°xima":
                        # Verifica se h√° valores n√£o nulos na coluna para calcular a data m√°xima.
                        if df[c].dropna().empty:
                            # Se a coluna estiver vazia ap√≥s remover nulos, pula para a pr√≥xima.
                            continue
                        # Preenche os valores nulos da coluna com a data m√°xima.
                        df[c] = df[c].fillna(df[c].max())

        # Atualiza o DataFrame na sess√£o do Streamlit com as altera√ß√µes.
        st.session_state.df = df
        # Calcula o n√∫mero de linhas removidas.
        removed = before - df.shape[0]
        # Registra a a√ß√£o no log, informando o n√∫mero de linhas removidas.
        log_step(f"Tratamento de nulos aplicado. Linhas removidas: {removed}.")
        # Exibe uma mensagem de sucesso na interface do Streamlit.
        st.success(f"Aplicado! Linhas removidas: {removed}")

# 6) Outliers (opcional)
with st.expander("6) üìâ Outliers (IQR) - opcional", expanded=False):
    # Exibe uma mensagem informativa para o usu√°rio sobre a funcionalidade de remo√ß√£o de outliers.
    st.write("Remove linhas com outliers em colunas num√©ricas usando IQR (Q1-1.5*IQR, Q3+1.5*IQR).")
    # Filtra as colunas do DataFrame que s√£o de tipo num√©rico.
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    # Cria um multiselect para o usu√°rio escolher quais colunas num√©ricas avaliar para outliers.
    cols_out = st.multiselect("Colunas para avaliar outliers", options=num_cols, default=[])
    # Cria um slider para o usu√°rio ajustar o fator IQR (multiplicador para o intervalo interquartil).
    iqr_factor = st.slider("Fator IQR", min_value=1.0, max_value=3.0, value=1.5, step=0.1)

    # Cria um bot√£o para aplicar a remo√ß√£o de outliers, desabilitado se nenhuma coluna for selecionada.
    if st.button("Remover outliers", key="apply_outliers", disabled=(len(cols_out) == 0)):
        # Armazena o n√∫mero de linhas antes da remo√ß√£o para calcular quantas foram removidas.
        before = df.shape[0]
        # Inicializa uma m√°scara booleana com True para todas as linhas.
        mask = pd.Series(True, index=df.index)
        # Itera sobre cada coluna selecionada para avalia√ß√£o de outliers.
        for c in cols_out:
            # Seleciona a s√©rie (coluna) atual do DataFrame.
            s = df[c]
            # Calcula o primeiro quartil (Q1).
            q1 = s.quantile(0.25)
            # Calcula o terceiro quartil (Q3).
            q3 = s.quantile(0.75)
            # Calcula o intervalo interquartil (IQR).
            iqr = q3 - q1
            # Calcula o limite inferior para detec√ß√£o de outliers.
            low = q1 - iqr_factor * iqr
            # Calcula o limite superior para detec√ß√£o de outliers.
            high = q3 + iqr_factor * iqr
            # Atualiza a m√°scara para incluir apenas os valores dentro dos limites IQR ou que s√£o nulos.
            mask &= s.between(low, high) | s.isna()
        # Filtra o DataFrame usando a m√°scara atualizada e cria uma c√≥pia.
        df = df[mask].copy()
        # Atualiza o DataFrame no estado da sess√£o do Streamlit.
        st.session_state.df = df
        # Calcula o n√∫mero de linhas removidas.
        removed = before - df.shape[0]
        # Registra a a√ß√£o no log de passos.
        log_step(f"Outliers removidos por IQR em {len(cols_out)} colunas. Linhas removidas: {removed}.")
        # Exibe uma mensagem de sucesso na interface do Streamlit.
        st.success(f"Aplicado! Linhas removidas: {removed}")

# 7) Remover colunas (opcional)

with st.expander("7) üßπ Remover colunas desnecess√°rias - opcional", expanded=False):
    # Cria um widget multiselect no Streamlit para o usu√°rio selecionar quais colunas deseja remover.
    # As op√ß√µes s√£o todos os nomes de colunas do DataFrame atual, e por padr√£o nenhuma √© pr√©-selecionada.
    drop_cols = st.multiselect("Selecione colunas para remover", options=list(df.columns), default=[])
    # Cria um bot√£o no Streamlit para aplicar a remo√ß√£o das colunas selecionadas.
    # O bot√£o √© desabilitado se a lista `drop_cols` estiver vazia (ou seja, nenhuma coluna selecionada).
    if st.button("Remover colunas selecionadas", key="apply_dropcols", disabled=(len(drop_cols) == 0)):
        # Remove as colunas especificadas na lista `drop_cols` do DataFrame.
        # `errors="ignore"` evita que um erro seja levantado se uma coluna em `drop_cols` n√£o existir no DataFrame.
        df = df.drop(columns=drop_cols, errors="ignore")
        # Atualiza o DataFrame armazenado no estado da sess√£o do Streamlit com as colunas removidas.
        st.session_state.df = df
        # Registra a a√ß√£o de remo√ß√£o de colunas no log de passos da aplica√ß√£o.
        log_step(f"Colunas removidas: {drop_cols}")
        # Exibe uma mensagem de sucesso na interface do Streamlit.
        st.success("Aplicado!")

st.divider()


# Log e Download final

# Cria duas colunas na interface do Streamlit, com propor√ß√µes de largura iguais (1 para 1) e um espa√ßamento "large"
left, right = st.columns([1, 1], gap="large")

# Inicia um bloco de c√≥digo que ser√° renderizado na primeira coluna (left)
with left:
    # Adiciona um subt√≠tulo √† coluna para o log de a√ß√µes
    st.subheader("üßæ Log do que foi feito")
    # Verifica se a lista de log no estado da sess√£o est√° vazia
    if len(st.session_state.log) == 0:
        # Se estiver vazia, exibe uma mensagem informativa
        st.info("Nenhuma etapa aplicada ainda.")
    # Se houver itens no log
    else:
        # Itera sobre cada mensagem no log, com um contador come√ßando de 1
        for i, msg in enumerate(st.session_state.log, start=1):
            # Exibe cada mensagem do log formatada com seu n√∫mero
            st.write(f"{i}. {msg}")

# Inicia um bloco de c√≥digo que ser√° renderizado na segunda coluna (right)
with right:
    # Adiciona um subt√≠tulo √† coluna para a se√ß√£o de exporta√ß√£o
    st.subheader("‚úÖ Exportar")
    # Cria um campo de texto para o usu√°rio definir o nome do arquivo de sa√≠da, com um valor padr√£o
    nome_saida = st.text_input("Nome do arquivo de sa√≠da", value="dados_tratados.csv")
    # Chama a fun√ß√£o download_button_csv para criar um bot√£o de download com o DataFrame atual e o nome/separador especificados
    download_button_csv(st.session_state.df, filename=nome_saida, sep=";")

# Adiciona uma pequena dica/legenda na parte inferior da interface
st.caption("Dica: se quiser voltar ao in√≠cio, use **Resetar tudo** na barra lateral.")
