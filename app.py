# Importa a biblioteca Streamlit para criar a interface web
import streamlit as st
# Importa a biblioteca pandas para manipula√ß√£o de dados em DataFrames
import pandas as pd
# Importa a biblioteca numpy para opera√ß√µes num√©ricas, embora n√£o explicitamente usada na sele√ß√£o, √© comum com pandas
import numpy as np
# Importa o m√≥dulo io para trabalhar com fluxos de bytes/arquivos em mem√≥ria
import io
# Importa o m√≥dulo re para express√µes regulares, usado em fun√ß√µes de utilidade
import re
# Importa a biblioteca chardet para detec√ß√£o de codifica√ß√£o de arquivos
import chardet
# Importa o parser de data da biblioteca dateutil para an√°lise flex√≠vel de datas
from dateutil import parser

# Configura√ß√µes iniciais da p√°gina Streamlit, como t√≠tulo e layout
st.set_page_config(page_title="Limpeza de Dados CSV", layout="wide")


# Utilit√°rios


# Define uma fun√ß√£o para detectar a codifica√ß√£o de um arquivo a partir de seus bytes
def detect_encoding(file_bytes: bytes) -> str:
    # Usa a biblioteca chardet para detectar a codifica√ß√£o dos bytes do arquivo
    result = chardet.detect(file_bytes)
    # Extrai a codifica√ß√£o do resultado, ou assume "utf-8" se n√£o for detectada
    enc = result.get("encoding") or "utf-8"
    # Retorna a codifica√ß√£o detectada ou padr√£o
    return enc

# Define uma fun√ß√£o para normalizar o nome de uma coluna
def normalize_colname(name: str) -> str:
    # Importa a biblioteca re para express√µes regulares (j√° importada no topo, mas re-importada aqui localmente)
    import re
    # Converte o nome para string, remove espa√ßos extras no in√≠cio/fim e converte para min√∫sculas
    name = str(name).strip().lower()
    # Substitui um ou mais espa√ßos por um √∫nico underscore
    name = re.sub(r"\s+", "_", name)
    # Remove todos os caracteres que n√£o s√£o letras, n√∫meros ou underscores
    name = re.sub(r"[^\w_]", "", name)
    # Substitui m√∫ltiplos underscores consecutivos por um √∫nico underscore e remove underscores no in√≠cio/fim
    name = re.sub(r"_+", "_", name).strip("_")
    # Se o nome resultar em uma string vazia ap√≥s a normaliza√ß√£o, define como "col"
    if name == "":
        name = "col"
    # Retorna o nome da coluna normalizado
    return name



# Define uma fun√ß√£o chamada make_unique que recebe uma lista de nomes
def make_unique(names):
    """Garante nomes √∫nicos: a, a_2, a_3...""" # Docstring: explica o prop√≥sito da fun√ß√£o
    seen = {} # Inicializa um dicion√°rio vazio para armazenar a contagem de cada nome
    out = [] # Inicializa uma lista vazia para armazenar os nomes √∫nicos resultantes
    # Itera sobre cada nome na lista de nomes de entrada
    for n in names:
        # Verifica se o nome atual ainda n√£o foi visto (n√£o est√° no dicion√°rio seen)
        if n not in seen:
            seen[n] = 1 # Se n√£o foi visto, adiciona-o ao dicion√°rio com contagem 1
            out.append(n) # Adiciona o nome original √† lista de sa√≠da
        # Se o nome j√° foi visto
        else:
            seen[n] += 1 # Incrementa a contagem desse nome no dicion√°rio
            out.append(f"{n}_{seen[n]}") # Adiciona o nome com um sufixo num√©rico (ex: "nome_2") √† lista de sa√≠da
    return out # Retorna a lista de nomes √∫nicos

def try_parse_datetime(series: pd.Series, sample_size=200) -> bool:
    # Define uma fun√ß√£o para tentar inferir se uma s√©rie Pandas cont√©m datas
    # A fun√ß√£o recebe uma s√©rie Pandas e um tamanho de amostra (padr√£o 200)
    # E retorna True se uma alta porcentagem da amostra for convert√≠vel para data, False caso contr√°rio

    # Extrai valores n√£o nulos da s√©rie e converte-os para string
    s = series.dropna().astype(str)
    # Se a s√©rie resultante estiver vazia ap√≥s remover nulos, n√£o h√° o que verificar, retorna False
    if s.empty:
        return False
    # Seleciona uma amostra aleat√≥ria dos valores (ou todos se o tamanho da s√©rie for menor que sample_size)
    # O random_state garante reprodutibilidade da amostra
    s = s.sample(min(sample_size, len(s)), random_state=42)
    # Inicializa um contador para o n√∫mero de valores que puderam ser parseados como data
    ok = 0
    # Itera sobre cada valor na amostra
    for v in s:
        try:
            # Tenta fazer o parse do valor para datetime usando o parser flex√≠vel da dateutil
            # fuzzy=True permite ignorar partes da string que n√£o s√£o datas (ex: "relat√≥rio 2023-01-01")
            _ = parser.parse(v, fuzzy=True)
            # Se o parse for bem-sucedido, incrementa o contador 'ok'
            ok += 1
        except Exception:
            # Se ocorrer um erro ao tentar o parse (o valor n√£o √© uma data v√°lida), ignora
            pass
    # Retorna True se pelo menos 70% (0.7) dos valores da amostra puderam ser parseados como data, caso contr√°rio False
    return (ok / len(s)) >= 0.7

# Define uma fun√ß√£o chamada to_datetime_safe que recebe uma s√©rie Pandas
def to_datetime_safe(series: pd.Series) -> pd.Series:
    # Tenta converter a s√©rie para o tipo datetime do Pandas
    # errors="coerce" far√° com que valores que n√£o podem ser convertidos se tornem NaT (Not a Time)
    # infer_datetime_format=True permite que o Pandas tente inferir o formato da data para uma convers√£o mais r√°pida
    return pd.to_datetime(series, errors="coerce", infer_datetime_format=True)

def coerce_numeric(series: pd.Series) -> pd.Series:
    # tenta converter removendo separadores comuns
    s = series.astype(str).str.strip()
    # troca v√≠rgula decimal por ponto quando parece num√©rico
    s = s.str.replace(".", "", regex=False)  # remove separador de milhar comum (.)
    s = s.str.replace(",", ".", regex=False)  # decimal v√≠rgula -> ponto
    return pd.to_numeric(s, errors="coerce")

# Define uma fun√ß√£o chamada download_button_csv que recebe um DataFrame, um nome de arquivo e um separador
def download_button_csv(df: pd.DataFrame, filename="dados_tratados.csv", sep=";"):
    # Converte o DataFrame para uma string CSV, sem o √≠ndice, usando o separador especificado, e codifica para bytes com BOM (para Excel)
    csv_bytes = df.to_csv(index=False, sep=sep).encode("utf-8-sig")  # <- utf-8-sig pro Excel
    # Cria um bot√£o de download no Streamlit
    st.download_button(
        "‚¨áÔ∏è Baixar CSV tratado (Excel)", # Texto exibido no bot√£o
        data=csv_bytes,                 # Dados a serem baixados
        file_name=filename,             # Nome do arquivo quando baixado
        mime="text/csv",                # Tipo MIME do arquivo
        use_container_width=True        # O bot√£o ocupa a largura total do cont√™iner
    )


# Define uma fun√ß√£o chamada df_info_summary que recebe um DataFrame e retorna um novo DataFrame com um resumo das colunas
def df_info_summary(df: pd.DataFrame) -> pd.DataFrame:
    # Retorna um novo DataFrame com informa√ß√µes sumarizadas de cada coluna do DataFrame de entrada
    return pd.DataFrame({
        "coluna": df.columns,                                       # Lista os nomes das colunas
        "dtype": [str(df[c].dtype) for c in df.columns],            # Lista os tipos de dados de cada coluna (como string)
        "nulos": [int(df[c].isna().sum()) for c in df.columns],     # Conta o n√∫mero de valores nulos em cada coluna
        "percent_nulos": [float(df[c].isna().mean() * 100) for c in df.columns], # Calcula o percentual de nulos em cada coluna
        "unicos": [int(df[c].nunique(dropna=True)) for c in df.columns], # Conta o n√∫mero de valores √∫nicos (ignorando nulos) em cada coluna
    })


# Estado

# Verifica se a chave 'df_original' n√£o existe no st.session_state (estado da sess√£o do Streamlit)
if "df_original" not in st.session_state:
    # Se n√£o existir, inicializa 'df_original' como None no estado da sess√£o
    st.session_state.df_original = None
# Verifica se a chave 'df' n√£o existe no st.session_state
if "df" not in st.session_state:
    # Se n√£o existir, inicializa 'df' como None no estado da sess√£o (este ser√° o DataFrame atual modificado)
    st.session_state.df = None
# Verifica se a chave 'log' n√£o existe no st.session_state
if "log" not in st.session_state:
    # Se n√£o existir, inicializa 'log' como uma lista vazia no estado da sess√£o (para registrar as a√ß√µes)
    st.session_state.log = []

# Define uma fun√ß√£o chamada 'log_step' que aceita uma mensagem (string)
def log_step(msg: str):
    # Adiciona a mensagem fornecida √† lista 'log' no estado da sess√£o
    st.session_state.log.append(msg)


# UI

# Define o t√≠tulo principal da aplica√ß√£o Streamlit
st.title("üßº Limpeza de Dados (CSV)")
# Adiciona uma pequena descri√ß√£o/legenda abaixo do t√≠tulo
st.caption("Upload ‚Üí Diagn√≥stico ‚Üí Limpeza em etapas ‚Üí Download do CSV tratado")

# Inicia um bloco de c√≥digo que ser√° renderizado na barra lateral do Streamlit
with st.sidebar:
    # Adiciona um cabe√ßalho para a se√ß√£o de upload na barra lateral
    st.header("üì• Upload")
    # Cria um widget de upload de arquivo para arquivos CSV
    uploaded = st.file_uploader("Selecione um arquivo CSV", type=["csv"])

    # Adiciona um divisor visual na barra lateral
    st.divider()
    # Adiciona um cabe√ßalho para a se√ß√£o de configura√ß√µes de leitura
    st.header("‚öôÔ∏è Configura√ß√µes de leitura")
    # Cria um seletor para o separador de colunas do CSV, com "," como padr√£o
    sep = st.selectbox("Separador", options=[",", ";", "\t", "|"], index=0)
    # Cria um seletor para o separador decimal (apenas para refer√™ncia na UI, n√£o afeta leitura diretamente aqui)
    decimal = st.selectbox("Decimal (apenas refer√™ncia)", options=[".", ","], index=0)
    # Cria uma caixa de sele√ß√£o para indicar se o CSV tem cabe√ßalho, marcada como verdadeira por padr√£o
    has_header = st.checkbox("Arquivo tem cabe√ßalho?", value=True)
    # Cria um campo de texto para o usu√°rio inserir valores a serem considerados como NA (Not Applicable/Nulo)
    na_values_text = st.text_input("Valores para considerar como NA (separe por v√≠rgula)", "NA,NaN,null,NULL,")
    # Processa a string de NA_values para criar uma lista de strings, removendo espa√ßos e entradas vazias
    na_values = [x.strip() for x in na_values_text.split(",") if x.strip() != ""]
    # Adiciona outro divisor visual na barra lateral
    st.divider()

    # Cria um bot√£o "Resetar tudo" na barra lateral
    if st.button("üîÑ Resetar tudo", use_container_width=True):
        # Quando clicado, redefine o DataFrame original para None no estado da sess√£o
        st.session_state.df_original = None
        # Redefine o DataFrame atual para None no estado da sess√£o
        st.session_state.df = None
        # Limpa o log de a√ß√µes no estado da sess√£o
        st.session_state.log = []
        # For√ßa o Streamlit a reroduzir o script desde o in√≠cio, limpando a UI e o estado
        st.rerun()


# Carregar CSV

# Verifica se um arquivo foi carregado (uploaded √© diferente de None) E se o DataFrame atual ainda n√£o foi carregado na sess√£o
if uploaded is not None and st.session_state.df is None:
    # Obt√©m o conte√∫do do arquivo carregado como bytes
    file_bytes = uploaded.getvalue()
    # Detecta a codifica√ß√£o do arquivo usando a fun√ß√£o 'detect_encoding'
    enc = detect_encoding(file_bytes)

    try:
        # Tenta ler o arquivo CSV usando pandas.read_csv
        df = pd.read_csv(
            # Cria um fluxo de bytes em mem√≥ria a partir dos bytes do arquivo
            io.BytesIO(file_bytes),
            # Define o separador de colunas conforme selecionado na UI
            sep=sep,
            # Define a codifica√ß√£o detectada
            encoding=enc,
            # Define o cabe√ßalho: 0 se 'has_header' for True, None caso contr√°rio
            header=0 if has_header else None,
            # Define os valores a serem considerados como NA (nulos)
            na_values=na_values
        )
    except Exception:
        # Em caso de erro na leitura com a codifica√ß√£o detectada, tenta um fallback simples
        df = pd.read_csv(
            # Cria um fluxo de bytes em mem√≥ria a partir dos bytes do arquivo
            io.BytesIO(file_bytes),
            # Define o separador de colunas conforme selecionado na UI
            sep=sep,
            # Usa "utf-8" como codifica√ß√£o de fallback
            encoding="utf-8",
            # Define o cabe√ßalho: 0 se 'has_header' for True, None caso contr√°rio
            header=0 if has_header else None,
            # Define os valores a serem considerados como NA (nulos)
            na_values=na_values
        )

    # Se o arquivo n√£o tiver cabe√ßalho (has_header √© False)
    if not has_header:
        # Atribui nomes de coluna gen√©ricos (ex: "col_0", "col_1")
        df.columns = [f"col_{i}" for i in range(df.shape[1])]

    # Armazena uma c√≥pia do DataFrame original no estado da sess√£o
    st.session_state.df_original = df.copy()
    # Armazena uma c√≥pia do DataFrame atual (que ser√° modificado) no estado da sess√£o
    st.session_state.df = df.copy()
    # Reinicia o log de a√ß√µes
    st.session_state.log = []
    # Registra a a√ß√£o de carregamento do arquivo no log
    log_step(f"Arquivo carregado com {df.shape[0]} linhas e {df.shape[1]} colunas. (encoding detectado: {enc})")

# Atribui o DataFrame atual da sess√£o (st.session_state.df) √† vari√°vel local 'df'
df = st.session_state.df

# Verifica se o DataFrame 'df' √© None (o que significa que nenhum arquivo foi carregado ainda)
if df is None:
    # Exibe uma mensagem informativa na interface do Streamlit
    st.info("Fa√ßa o upload de um CSV na barra lateral para come√ßar.")
    # Interrompe a execu√ß√£o do script Streamlit neste ponto, aguardando o upload do arquivo
    st.stop()


# Vis√£o geral

colA, colB = st.columns([2, 1], gap="large")

with colA:
    st.subheader("Pr√©via do dataset")
    st.dataframe(df.head(50), use_container_width=True)

with colB:
    st.subheader("üìä Resumo")
    st.write(f"**Linhas:** {df.shape[0]}")
    st.write(f"**Colunas:** {df.shape[1]}")
    st.write(f"**Duplicadas (linhas):** {int(df.duplicated().sum())}")
    st.write(f"**C√©lulas nulas (total):** {int(df.isna().sum().sum())}")
    st.write("")
    st.caption("Detalhe por coluna:")
    st.dataframe(df_info_summary(df), use_container_width=True, height=260)

st.divider()

# ---------------------------
# Etapas (Acorde√µes)
# ---------------------------

# 1) Padronizar nomes de colunas
with st.expander("1) üè∑Ô∏è Padronizar nomes de colunas", expanded=False):
    st.write("Sugest√£o: remover espa√ßos, padronizar para min√∫sculas e trocar espa√ßos por `_`.")
    preview_cols = pd.DataFrame({
        "antes": st.session_state.df.columns,
        "depois": [normalize_colname(c) for c in st.session_state.df.columns]
    })
    st.dataframe(preview_cols, use_container_width=True)
    
    dups = pd.Series([normalize_colname(c) for c in df.columns]).duplicated().sum()
    st.write(f"Poss√≠veis nomes duplicados ap√≥s padronizar: **{int(dups)}**")

    if st.button("Aplicar padroniza√ß√£o de nomes", key="apply_colnames"):
        old_cols = list(df.columns)
        new_cols = [normalize_colname(c) for c in old_cols]
        new_cols = make_unique(new_cols)

        df = df.copy()
        df.columns = new_cols
        st.session_state.df = df

        log_step("Nomes de colunas padronizados e tornados √∫nicos.")
        st.success("Aplicado!")
        st.rerun()


# 2) Remover espa√ßos extras em textos
with st.expander("2) ‚úÇÔ∏è Limpar textos (trim, espa√ßos duplicados)", expanded=False):
    text_cols = [c for c in df.columns if df[c].dtype == "object"]
    selected = st.multiselect("Selecione colunas de texto", options=text_cols, default=text_cols[:10])
    replace_multi_space = st.checkbox("Trocar m√∫ltiplos espa√ßos por 1 espa√ßo", value=True)
    if st.button("Aplicar limpeza de texto", key="apply_text"):
        for c in selected:
            s = df[c].astype("string")
            s = s.str.strip()
            if replace_multi_space:
                s = s.str.replace(r"\s+", " ", regex=True)
            df[c] = s
        st.session_state.df = df
        log_step(f"Limpeza de texto aplicada em {len(selected)} colunas (strip + normaliza√ß√£o de espa√ßos).")
        st.success("Aplicado!")

# 3) Tipagem autom√°tica (datas e n√∫meros)
with st.expander("3) üî¢ Tipagem autom√°tica (detectar datas e n√∫meros)", expanded=False):
    st.write("Converte colunas `object` que parecem n√∫meros/datas.")
    convert_numbers = st.checkbox("Tentar converter n√∫meros (ex: '1.234,56')", value=True)
    convert_dates = st.checkbox("Tentar converter datas", value=True)

    if st.button("Aplicar tipagem autom√°tica", key="apply_types"):
        changed = 0

        # n√∫meros
        if convert_numbers:
            for c in df.columns:
                if df[c].dtype == "object":
                    # tenta converter e mede ganho
                    converted = coerce_numeric(df[c])
                    # crit√©rio: se converter >= 70% dos n√£o-nulos vira num√©rico, aplica
                    non_null = df[c].notna().sum()
                    if non_null > 0:
                        ratio = converted.notna().sum() / non_null
                        if ratio >= 0.7:
                            df[c] = converted
                            changed += 1

        # datas
        if convert_dates:
            for c in df.columns:
                if df[c].dtype == "object":
                    if try_parse_datetime(df[c]):
                        dt = to_datetime_safe(df[c])
                        if dt.notna().sum() >= 0.7 * df[c].notna().sum():
                            df[c] = dt
                            changed += 1

        st.session_state.df = df
        log_step(f"Tipagem autom√°tica aplicada. Colunas convertidas: {changed}.")
        st.success(f"Aplicado! Colunas convertidas: {changed}")

# 4) Duplicadas
with st.expander("4) üß© Remover linhas duplicadas", expanded=False):
    dups = int(df.duplicated().sum())
    st.write(f"Duplicadas detectadas: **{dups}**")
    keep = st.selectbox("Manter qual ocorr√™ncia?", options=["first", "last"], index=0)
    if st.button("Remover duplicadas", key="apply_dups", disabled=(dups == 0)):
        before = df.shape[0]
        df = df.drop_duplicates(keep=keep)
        st.session_state.df = df
        log_step(f"Linhas duplicadas removidas (keep='{keep}'). {before - df.shape[0]} linhas removidas.")
        st.success("Aplicado!")

# 5) Valores nulos
with st.expander("5) üï≥Ô∏è Tratamento de valores nulos", expanded=False):
    st.write("Escolha uma estrat√©gia por tipo de coluna.")
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    cat_cols = [c for c in df.columns if df[c].dtype == "object" or pd.api.types.is_string_dtype(df[c])]
    dt_cols  = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]

    st.markdown("**Num√©ricas:**")
    num_strategy = st.selectbox("Estrat√©gia (num√©ricas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com 0", "Preencher com m√©dia", "Preencher com mediana"], index=0)
    num_sel = st.multiselect("Colunas num√©ricas", options=num_cols, default=num_cols)

    st.markdown("**Categ√≥ricas/Textos:**")
    cat_strategy = st.selectbox("Estrat√©gia (categ√≥ricas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com 'DESCONHECIDO'", "Preencher com moda (mais frequente)"], index=0)
    cat_sel = st.multiselect("Colunas categ√≥ricas", options=cat_cols, default=cat_cols)

    st.markdown("**Datas:**")
    dt_strategy = st.selectbox("Estrat√©gia (datas)", ["N√£o mexer", "Remover linhas com NA", "Preencher com data m√≠nima", "Preencher com data m√°xima"], index=0)
    dt_sel = st.multiselect("Colunas datetime", options=dt_cols, default=dt_cols)

    if st.button("Aplicar tratamento de nulos", key="apply_na"):
        before = df.shape[0]

        # num√©ricas
        if num_strategy != "N√£o mexer" and len(num_sel) > 0:
            if num_strategy == "Remover linhas com NA":
                df = df.dropna(subset=num_sel)
            else:
                for c in num_sel:
                    if num_strategy == "Preencher com 0":
                        df[c] = df[c].fillna(0)
                    elif num_strategy == "Preencher com m√©dia":
                        df[c] = df[c].fillna(df[c].mean())
                    elif num_strategy == "Preencher com mediana":
                        df[c] = df[c].fillna(df[c].median())

        # categ√≥ricas
        if cat_strategy != "N√£o mexer" and len(cat_sel) > 0:
            if cat_strategy == "Remover linhas com NA":
                df = df.dropna(subset=cat_sel)
            else:
                for c in cat_sel:
                    if cat_strategy == "Preencher com 'DESCONHECIDO'":
                        df[c] = df[c].fillna("DESCONHECIDO")
                    elif cat_strategy == "Preencher com moda (mais frequente)":
                        moda = df[c].mode(dropna=True)
                        fill = moda.iloc[0] if len(moda) else "DESCONHECIDO"
                        df[c] = df[c].fillna(fill)

        # datas
        if dt_strategy != "N√£o mexer" and len(dt_sel) > 0:
            if dt_strategy == "Remover linhas com NA":
                df = df.dropna(subset=dt_sel)
            else:
                for c in dt_sel:
                    if dt_strategy == "Preencher com data m√≠nima":
                        if df[c].dropna().empty:
                            continue
                        df[c] = df[c].fillna(df[c].min())
                    elif dt_strategy == "Preencher com data m√°xima":
                        if df[c].dropna().empty:
                            continue
                        df[c] = df[c].fillna(df[c].max())

        st.session_state.df = df
        removed = before - df.shape[0]
        log_step(f"Tratamento de nulos aplicado. Linhas removidas: {removed}.")
        st.success(f"Aplicado! Linhas removidas: {removed}")

# 6) Outliers (opcional)
with st.expander("6) üìâ Outliers (IQR) - opcional", expanded=False):
    st.write("Remove linhas com outliers em colunas num√©ricas usando IQR (Q1-1.5*IQR, Q3+1.5*IQR).")
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    cols_out = st.multiselect("Colunas para avaliar outliers", options=num_cols, default=[])
    iqr_factor = st.slider("Fator IQR", min_value=1.0, max_value=3.0, value=1.5, step=0.1)

    if st.button("Remover outliers", key="apply_outliers", disabled=(len(cols_out) == 0)):
        before = df.shape[0]
        mask = pd.Series(True, index=df.index)
        for c in cols_out:
            s = df[c]
            q1 = s.quantile(0.25)
            q3 = s.quantile(0.75)
            iqr = q3 - q1
            low = q1 - iqr_factor * iqr
            high = q3 + iqr_factor * iqr
            mask &= s.between(low, high) | s.isna()
        df = df[mask].copy()
        st.session_state.df = df
        removed = before - df.shape[0]
        log_step(f"Outliers removidos por IQR em {len(cols_out)} colunas. Linhas removidas: {removed}.")
        st.success(f"Aplicado! Linhas removidas: {removed}")

# 7) Remover colunas (opcional)
with st.expander("7) üßπ Remover colunas desnecess√°rias - opcional", expanded=False):
    drop_cols = st.multiselect("Selecione colunas para remover", options=list(df.columns), default=[])
    if st.button("Remover colunas selecionadas", key="apply_dropcols", disabled=(len(drop_cols) == 0)):
        df = df.drop(columns=drop_cols, errors="ignore")
        st.session_state.df = df
        log_step(f"Colunas removidas: {drop_cols}")
        st.success("Aplicado!")

st.divider()

# ---------------------------
# Log e Download final
# ---------------------------
left, right = st.columns([1, 1], gap="large")

with left:
    st.subheader("üßæ Log do que foi feito")
    if len(st.session_state.log) == 0:
        st.info("Nenhuma etapa aplicada ainda.")
    else:
        for i, msg in enumerate(st.session_state.log, start=1):
            st.write(f"{i}. {msg}")

with right:
    st.subheader("‚úÖ Exportar")
    nome_saida = st.text_input("Nome do arquivo de sa√≠da", value="dados_tratados.csv")
    download_button_csv(st.session_state.df, filename=nome_saida, sep=";")


st.caption("Dica: se quiser voltar ao in√≠cio, use **Resetar tudo** na barra lateral.")
